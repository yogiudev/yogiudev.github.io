"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1043],{62:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"guides/langraph-advanced","title":"LangGraph: Advanced","description":"Real-World Use Case: MongoDB Intelligence Platform","source":"@site/docs/guides/langraph-advanced.md","sourceDirName":"guides","slug":"/guides/langraph-advanced","permalink":"/docs/guides/langraph-advanced","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/guides/langraph-advanced.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"LangGraph","permalink":"/docs/guides/langgraph"},"next":{"title":"mongodb-queries","permalink":"/docs/guides/mongodb-queries"}}');var s=t(4848),r=t(8453);const a={},o="LangGraph: Advanced",l={},c=[{value:"Real-World Use Case: MongoDB Intelligence Platform",id:"real-world-use-case-mongodb-intelligence-platform",level:2},{value:"Use Case Overview",id:"use-case-overview",level:3},{value:"System Architecture",id:"system-architecture",level:2},{value:"Step 1: Define the Enhanced State Schema",id:"step-1-define-the-enhanced-state-schema",level:3},{value:"Step 2: Initialize Components and Metadata",id:"step-2-initialize-components-and-metadata",level:3},{value:"Step 3: Build the Intelligence Agents",id:"step-3-build-the-intelligence-agents",level:3},{value:"Step 4: Define Intelligent Routing",id:"step-4-define-intelligent-routing",level:3},{value:"2. <strong>Token Usage Optimization</strong>",id:"2-token-usage-optimization",level:3},{value:"3. <strong>Advanced Performance Monitoring</strong>",id:"3-advanced-performance-monitoring",level:3},{value:"4. <strong>Smart Query Optimization</strong>",id:"4-smart-query-optimization",level:3},{value:"Production Best Practices",id:"production-best-practices",level:2},{value:"1. <strong>Scalability Patterns</strong>",id:"1-scalability-patterns",level:3},{value:"2. <strong>Error Recovery and Resilience</strong>",id:"2-error-recovery-and-resilience",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"langgraph-advanced",children:"LangGraph: Advanced"})}),"\n",(0,s.jsx)(n.h1,{id:"ai-analytics-agent-for-mongodb",children:"AI Analytics Agent for MongoDB"}),"\n",(0,s.jsx)(n.h2,{id:"real-world-use-case-mongodb-intelligence-platform",children:"Real-World Use Case: MongoDB Intelligence Platform"}),"\n",(0,s.jsx)(n.p,{children:"Let's build a comprehensive AI analytics agent that transforms natural language queries into actionable insights from MongoDB. This system will showcase advanced LangGraph capabilities while providing analytics, predictions, and visualizations."}),"\n",(0,s.jsx)(n.h3,{id:"use-case-overview",children:"Use Case Overview"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Scenario"}),": DataFlow Inc. needs an AI-powered analytics platform that can:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Convert natural language to MongoDB queries"}),"\n",(0,s.jsx)(n.li,{children:"Generate insights and predictions"}),"\n",(0,s.jsx)(n.li,{children:"Create dynamic dashboards and visualizations"}),"\n",(0,s.jsx)(n.li,{children:"Perform external API enrichment"}),"\n",(0,s.jsx)(n.li,{children:"Optimize for token usage and performance"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-define-the-enhanced-state-schema",children:"Step 1: Define the Enhanced State Schema"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from typing import TypedDict, Annotated, List, Optional, Dict, Any\nfrom langgraph.graph.message import add_messages\nfrom datetime import datetime\nimport json\n\nclass AnalyticsState(TypedDict):\n    # Core conversation\n    messages: Annotated[List, add_messages]\n    \n    # Query processing\n    original_query: str\n    query_intent: str\n    query_complexity: str  # simple, medium, complex\n    \n    # MongoDB operations\n    generated_queries: List[Dict[str, Any]]\n    query_results: List[Dict[str, Any]]\n    collections_accessed: List[str]\n    \n    # Analytics components\n    insights_generated: List[str]\n    predictions: Dict[str, Any]\n    visualizations: List[Dict[str, Any]]\n    \n    # External data enrichment\n    external_apis_called: List[str]\n    enriched_data: Dict[str, Any]\n    \n    # Metadata and optimization\n    schema_info: Dict[str, Any]\n    feature_metadata: Dict[str, Any]\n    embeddings_cache: Dict[str, Any]\n    \n    # Performance tracking\n    token_usage: Dict[str, int]\n    query_execution_time: float\n    cache_hits: int\n    \n    # Control flow\n    needs_visualization: bool\n    needs_external_data: bool\n    needs_prediction: bool\n    confidence_score: float\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-2-initialize-components-and-metadata",children:"Step 2: Initialize Components and Metadata"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langgraph.graph import StateGraph, END, START\nimport pymongo\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nimport plotly.graph_objects as go\nimport requests\nimport time\n\n# Initialize components\nllm = ChatOpenAI(model="gpt-4", temperature=0.3)\nembeddings = OpenAIEmbeddings()\nmongo_client = pymongo.MongoClient("mongodb://localhost:27017/")\ndb = mongo_client.analytics_db\n\n# Sample schema and metadata\nSCHEMA_INFO = {\n    "users": {\n        "fields": ["user_id", "name", "email", "signup_date", "plan_type", "usage_stats"],\n        "indexes": ["user_id", "email", "signup_date"],\n        "sample_values": {\n            "plan_type": ["basic", "premium", "enterprise"],\n            "email": ["gmail.com", "outlook.com", "company.com"]\n        }\n    },\n    "orders": {\n        "fields": ["order_id", "user_id", "amount", "status", "created_at", "items"],\n        "indexes": ["order_id", "user_id", "created_at"],\n        "sample_values": {\n            "status": ["pending", "completed", "cancelled"],\n            "amount": {"min": 10, "max": 1000, "avg": 150}\n        }\n    },\n    "products": {\n        "fields": ["product_id", "name", "category", "price", "stock", "ratings"],\n        "indexes": ["product_id", "category", "price"],\n        "sample_values": {\n            "category": ["electronics", "clothing", "books", "home"],\n            "price": {"min": 5, "max": 500, "avg": 75}\n        }\n    },\n    "sessions": {\n        "fields": ["session_id", "user_id", "start_time", "duration", "pages_visited"],\n        "indexes": ["session_id", "user_id", "start_time"],\n        "sample_values": {\n            "duration": {"min": 30, "max": 3600, "avg": 300}\n        }\n    }\n}\n\nFEATURE_METADATA = {\n    "user_retention": {\n        "description": "Measures user engagement and retention rates",\n        "related_collections": ["users", "sessions", "orders"],\n        "key_metrics": ["login_frequency", "session_duration", "purchase_frequency"],\n        "prediction_target": "churn_probability"\n    },\n    "revenue_analysis": {\n        "description": "Analyzes revenue patterns and trends",\n        "related_collections": ["orders", "products", "users"],\n        "key_metrics": ["total_revenue", "average_order_value", "customer_lifetime_value"],\n        "prediction_target": "monthly_revenue"\n    },\n    "product_performance": {\n        "description": "Evaluates product success and inventory needs",\n        "related_collections": ["products", "orders", "users"],\n        "key_metrics": ["sales_volume", "revenue_per_product", "inventory_turnover"],\n        "prediction_target": "demand_forecast"\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-build-the-intelligence-agents",children:"Step 3: Build the Intelligence Agents"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def query_analyzer(state: AnalyticsState):\n    """Analyze user query and determine intent and complexity"""\n    start_time = time.time()\n    \n    user_query = state["original_query"]\n    \n    # Generate embedding for query similarity\n    query_embedding = embeddings.embed_query(user_query)\n    \n    analysis_prompt = f"""\n    Analyze this analytics query and classify it:\n    \n    Query: "{user_query}"\n    \n    Available schemas: {json.dumps(SCHEMA_INFO, indent=2)}\n    Available features: {json.dumps(FEATURE_METADATA, indent=2)}\n    \n    Determine:\n    1. Intent (analytics, prediction, visualization, data_extraction)\n    2. Complexity (simple, medium, complex)\n    3. Required collections (max 5-6)\n    4. Whether external data is needed\n    5. Confidence score (0-1)\n    \n    Respond in JSON format:\n    {{\n        "intent": "analytics|prediction|visualization|data_extraction",\n        "complexity": "simple|medium|complex",\n        "collections_needed": ["collection1", "collection2"],\n        "needs_external_data": true|false,\n        "needs_visualization": true|false,\n        "needs_prediction": true|false,\n        "confidence_score": 0.85\n    }}\n    """\n    \n    response = llm.invoke([{"role": "user", "content": analysis_prompt}])\n    analysis = json.loads(response.content)\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "query_intent": analysis["intent"],\n        "query_complexity": analysis["complexity"],\n        "collections_accessed": analysis["collections_needed"],\n        "needs_external_data": analysis["needs_external_data"],\n        "needs_visualization": analysis["needs_visualization"],\n        "needs_prediction": analysis["needs_prediction"],\n        "confidence_score": analysis["confidence_score"],\n        "query_execution_time": processing_time,\n        "token_usage": {"query_analyzer": len(response.content)},\n        "embeddings_cache": {"query": query_embedding}\n    }\n\ndef mongodb_query_generator(state: AnalyticsState):\n    """Generate optimized MongoDB queries"""\n    start_time = time.time()\n    \n    user_query = state["original_query"]\n    collections = state["collections_accessed"]\n    \n    # Generate queries for each collection\n    generated_queries = []\n    \n    for collection in collections:\n        schema = SCHEMA_INFO.get(collection, {})\n        \n        query_prompt = f"""\n        Generate an optimized MongoDB aggregation query for this request:\n        \n        User Query: "{user_query}"\n        Collection: {collection}\n        Schema: {json.dumps(schema, indent=2)}\n        \n        Create an efficient aggregation pipeline that:\n        1. Uses indexes when possible\n        2. Limits results to essential data\n        3. Includes necessary grouping/sorting\n        4. Optimizes for performance\n        \n        Return only the aggregation pipeline as a JSON array.\n        """\n        \n        response = llm.invoke([{"role": "user", "content": query_prompt}])\n        \n        try:\n            pipeline = json.loads(response.content)\n            generated_queries.append({\n                "collection": collection,\n                "pipeline": pipeline,\n                "estimated_docs": min(1000, schema.get("estimated_size", 100))\n            })\n        except json.JSONDecodeError:\n            # Fallback query\n            generated_queries.append({\n                "collection": collection,\n                "pipeline": [{"$limit": 100}],\n                "estimated_docs": 100\n            })\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "generated_queries": generated_queries,\n        "query_execution_time": state["query_execution_time"] + processing_time,\n        "token_usage": {\n            **state.get("token_usage", {}),\n            "query_generator": len(str(generated_queries))\n        }\n    }\n\ndef data_executor(state: AnalyticsState):\n    """Execute MongoDB queries and return results"""\n    start_time = time.time()\n    \n    queries = state["generated_queries"]\n    results = []\n    \n    for query_info in queries:\n        collection_name = query_info["collection"]\n        pipeline = query_info["pipeline"]\n        \n        try:\n            # Execute query with timeout\n            collection = db[collection_name]\n            cursor = collection.aggregate(pipeline, maxTimeMS=30000)\n            \n            # Convert to list and limit results\n            query_results = list(cursor)[:500]  # Limit to 500 docs\n            \n            results.append({\n                "collection": collection_name,\n                "data": query_results,\n                "count": len(query_results),\n                "execution_time": time.time() - start_time\n            })\n            \n        except Exception as e:\n            # Mock data for demonstration\n            results.append({\n                "collection": collection_name,\n                "data": generate_mock_data(collection_name),\n                "count": 50,\n                "execution_time": 0.1,\n                "error": str(e)\n            })\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "query_results": results,\n        "query_execution_time": state["query_execution_time"] + processing_time\n    }\n\ndef generate_mock_data(collection_name: str):\n    """Generate realistic mock data for demonstration"""\n    if collection_name == "users":\n        return [\n            {"user_id": i, "name": f"User {i}", "plan_type": "premium", "signup_date": "2024-01-15"}\n            for i in range(1, 51)\n        ]\n    elif collection_name == "orders":\n        return [\n            {"order_id": i, "user_id": i % 20, "amount": 150 + i, "status": "completed"}\n            for i in range(1, 51)\n        ]\n    elif collection_name == "products":\n        return [\n            {"product_id": i, "name": f"Product {i}", "category": "electronics", "price": 75 + i}\n            for i in range(1, 51)\n        ]\n    else:\n        return [{"id": i, "value": f"data_{i}"} for i in range(1, 51)]\n\ndef insights_generator(state: AnalyticsState):\n    """Generate analytical insights from query results"""\n    start_time = time.time()\n    \n    results = state["query_results"]\n    user_query = state["original_query"]\n    \n    # Analyze results and generate insights\n    insights = []\n    \n    for result in results:\n        collection = result["collection"]\n        data = result["data"]\n        \n        if not data:\n            continue\n            \n        # Generate collection-specific insights\n        if collection == "users":\n            total_users = len(data)\n            premium_users = sum(1 for u in data if u.get("plan_type") == "premium")\n            insights.append(f"Total active users: {total_users}")\n            insights.append(f"Premium users: {premium_users} ({premium_users/total_users*100:.1f}%)")\n            \n        elif collection == "orders":\n            total_orders = len(data)\n            total_revenue = sum(o.get("amount", 0) for o in data)\n            avg_order_value = total_revenue / total_orders if total_orders > 0 else 0\n            insights.append(f"Total orders: {total_orders}")\n            insights.append(f"Total revenue: ${total_revenue:,.2f}")\n            insights.append(f"Average order value: ${avg_order_value:.2f}")\n            \n        elif collection == "products":\n            total_products = len(data)\n            avg_price = sum(p.get("price", 0) for p in data) / total_products if total_products > 0 else 0\n            insights.append(f"Total products: {total_products}")\n            insights.append(f"Average product price: ${avg_price:.2f}")\n    \n    # Generate high-level insights\n    summary_prompt = f"""\n    Based on this data analysis, provide 3-5 key business insights:\n    \n    Query: "{user_query}"\n    Data Summary: {json.dumps(insights, indent=2)}\n    \n    Focus on:\n    1. Key trends and patterns\n    2. Business implications\n    3. Actionable recommendations\n    \n    Keep insights concise and business-focused.\n    """\n    \n    response = llm.invoke([{"role": "user", "content": summary_prompt}])\n    ai_insights = response.content.split(\'\\n\')\n    \n    all_insights = insights + [insight.strip() for insight in ai_insights if insight.strip()]\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "insights_generated": all_insights,\n        "query_execution_time": state["query_execution_time"] + processing_time,\n        "token_usage": {\n            **state.get("token_usage", {}),\n            "insights_generator": len(response.content)\n        }\n    }\n\ndef prediction_engine(state: AnalyticsState):\n    """Generate predictions based on data patterns"""\n    start_time = time.time()\n    \n    if not state.get("needs_prediction", False):\n        return {"predictions": {}}\n    \n    results = state["query_results"]\n    user_query = state["original_query"]\n    \n    predictions = {}\n    \n    # Find relevant feature metadata\n    relevant_feature = None\n    for feature, metadata in FEATURE_METADATA.items():\n        if any(keyword in user_query.lower() for keyword in metadata["key_metrics"]):\n            relevant_feature = feature\n            break\n    \n    if relevant_feature:\n        feature_info = FEATURE_METADATA[relevant_feature]\n        \n        # Generate predictions based on feature type\n        if relevant_feature == "revenue_analysis":\n            # Mock revenue prediction\n            historical_data = [150, 175, 200, 225, 250]  # Monthly revenue (thousands)\n            predicted_next_month = historical_data[-1] * 1.1\n            predictions["revenue_forecast"] = {\n                "next_month": f"${predicted_next_month:.0f}K",\n                "confidence": 0.85,\n                "trend": "increasing"\n            }\n            \n        elif relevant_feature == "user_retention":\n            # Mock churn prediction\n            predictions["churn_analysis"] = {\n                "high_risk_users": 45,\n                "churn_probability": 0.12,\n                "retention_rate": 0.88\n            }\n            \n        elif relevant_feature == "product_performance":\n            # Mock demand forecasting\n            predictions["demand_forecast"] = {\n                "high_demand_products": ["Product A", "Product B"],\n                "stock_alerts": ["Product C - Low Stock"],\n                "seasonal_trends": "Electronics peak expected in Q4"\n            }\n    \n    # Generate AI-powered predictions\n    prediction_prompt = f"""\n    Based on this data, generate relevant predictions:\n    \n    Query: "{user_query}"\n    Available Data: {json.dumps([r[\'collection\'] for r in results])}\n    \n    Provide predictions in JSON format with confidence scores.\n    """\n    \n    try:\n        response = llm.invoke([{"role": "user", "content": prediction_prompt}])\n        ai_predictions = json.loads(response.content)\n        predictions.update(ai_predictions)\n    except:\n        predictions["ai_insight"] = "Unable to generate additional predictions"\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "predictions": predictions,\n        "query_execution_time": state["query_execution_time"] + processing_time,\n        "token_usage": {\n            **state.get("token_usage", {}),\n            "prediction_engine": len(str(predictions))\n        }\n    }\n\ndef external_data_enricher(state: AnalyticsState):\n    """Enrich data with external API calls"""\n    start_time = time.time()\n    \n    if not state.get("needs_external_data", False):\n        return {"enriched_data": {}, "external_apis_called": []}\n    \n    user_query = state["original_query"]\n    apis_called = []\n    enriched_data = {}\n    \n    # Determine which APIs to call based on query\n    if "weather" in user_query.lower() or "location" in user_query.lower():\n        # Mock weather API call\n        weather_data = {\n            "temperature": 75,\n            "condition": "sunny",\n            "impact_on_sales": "positive"\n        }\n        enriched_data["weather"] = weather_data\n        apis_called.append("weather_api")\n    \n    if "market" in user_query.lower() or "competitors" in user_query.lower():\n        # Mock market data API\n        market_data = {\n            "market_trend": "growing",\n            "competitor_analysis": {\n                "competitor_a": {"market_share": 0.25, "growth_rate": 0.15},\n                "competitor_b": {"market_share": 0.20, "growth_rate": 0.10}\n            }\n        }\n        enriched_data["market"] = market_data\n        apis_called.append("market_api")\n    \n    if "industry" in user_query.lower() or "benchmark" in user_query.lower():\n        # Mock industry benchmarks\n        industry_data = {\n            "industry_average_conversion": 0.035,\n            "industry_average_cltv": 850,\n            "benchmarks": {\n                "customer_satisfaction": 4.2,\n                "response_time": 2.5\n            }\n        }\n        enriched_data["industry"] = industry_data\n        apis_called.append("industry_api")\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "enriched_data": enriched_data,\n        "external_apis_called": apis_called,\n        "query_execution_time": state["query_execution_time"] + processing_time\n    }\n\ndef visualization_generator(state: AnalyticsState):\n    """Generate visualizations and dashboard components"""\n    start_time = time.time()\n    \n    if not state.get("needs_visualization", False):\n        return {"visualizations": []}\n    \n    results = state["query_results"]\n    insights = state["insights_generated"]\n    \n    visualizations = []\n    \n    # Generate chart configurations\n    for result in results:\n        collection = result["collection"]\n        data = result["data"]\n        \n        if collection == "orders" and data:\n            # Revenue trend chart\n            revenue_chart = {\n                "type": "line",\n                "title": "Revenue Trend",\n                "data": {\n                    "x": [f"Month {i}" for i in range(1, 7)],\n                    "y": [15000, 18000, 22000, 25000, 28000, 32000]\n                },\n                "config": {\n                    "xaxis": {"title": "Time Period"},\n                    "yaxis": {"title": "Revenue ($)"}\n                }\n            }\n            visualizations.append(revenue_chart)\n            \n            # Order status pie chart\n            status_chart = {\n                "type": "pie",\n                "title": "Order Status Distribution",\n                "data": {\n                    "labels": ["Completed", "Pending", "Cancelled"],\n                    "values": [75, 20, 5]\n                }\n            }\n            visualizations.append(status_chart)\n            \n        elif collection == "users" and data:\n            # User growth chart\n            user_chart = {\n                "type": "bar",\n                "title": "User Growth by Plan Type",\n                "data": {\n                    "x": ["Basic", "Premium", "Enterprise"],\n                    "y": [1200, 800, 300]\n                },\n                "config": {\n                    "xaxis": {"title": "Plan Type"},\n                    "yaxis": {"title": "Number of Users"}\n                }\n            }\n            visualizations.append(user_chart)\n    \n    # Generate dashboard layout\n    dashboard_config = {\n        "layout": "grid",\n        "rows": 2,\n        "cols": 2,\n        "charts": visualizations,\n        "filters": ["date_range", "category", "user_segment"],\n        "refresh_interval": 300  # 5 minutes\n    }\n    \n    visualizations.append({\n        "type": "dashboard",\n        "title": "Analytics Dashboard",\n        "config": dashboard_config\n    })\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "visualizations": visualizations,\n        "query_execution_time": state["query_execution_time"] + processing_time,\n        "token_usage": {\n            **state.get("token_usage", {}),\n            "visualization_generator": len(str(visualizations))\n        }\n    }\n\ndef response_synthesizer(state: AnalyticsState):\n    """Synthesize final response with all components"""\n    start_time = time.time()\n    \n    user_query = state["original_query"]\n    insights = state["insights_generated"]\n    predictions = state["predictions"]\n    visualizations = state["visualizations"]\n    enriched_data = state["enriched_data"]\n    \n    # Create comprehensive response\n    response_sections = []\n    \n    # Executive Summary\n    summary = f"""\n    ## Analytics Summary for: "{user_query}"\n    \n    **Query processed in {state[\'query_execution_time\']:.2f} seconds**\n    - Collections analyzed: {len(state[\'collections_accessed\'])}\n    - Data points processed: {sum(r[\'count\'] for r in state[\'query_results\'])}\n    - Confidence score: {state[\'confidence_score\']:.2f}\n    """\n    response_sections.append(summary)\n    \n    # Key Insights\n    if insights:\n        insights_section = "## Key Insights\\n\\n"\n        for i, insight in enumerate(insights[:5], 1):\n            insights_section += f"{i}. {insight}\\n"\n        response_sections.append(insights_section)\n    \n    # Predictions\n    if predictions:\n        pred_section = "## Predictions & Forecasts\\n\\n"\n        for key, value in predictions.items():\n            if isinstance(value, dict):\n                pred_section += f"**{key.replace(\'_\', \' \').title()}:**\\n"\n                for k, v in value.items():\n                    pred_section += f"- {k}: {v}\\n"\n            else:\n                pred_section += f"- {key}: {value}\\n"\n        response_sections.append(pred_section)\n    \n    # Visualizations\n    if visualizations:\n        viz_section = "## Visualizations Available\\n\\n"\n        for viz in visualizations:\n            viz_section += f"- {viz[\'title\']} ({viz[\'type\']})\\n"\n        response_sections.append(viz_section)\n    \n    # External Data\n    if enriched_data:\n        ext_section = "## External Data Insights\\n\\n"\n        for source, data in enriched_data.items():\n            ext_section += f"**{source.title()}:** {str(data)[:100]}...\\n"\n        response_sections.append(ext_section)\n    \n    # Performance Metrics\n    performance_section = f"""\n    ## Performance Metrics\n    - Total execution time: {state[\'query_execution_time\']:.2f}s\n    - Token usage: {sum(state.get(\'token_usage\', {}).values())}\n    - Cache hits: {state.get(\'cache_hits\', 0)}\n    - APIs called: {len(state.get(\'external_apis_called\', []))}\n    """\n    response_sections.append(performance_section)\n    \n    final_response = "\\n\\n".join(response_sections)\n    \n    processing_time = time.time() - start_time\n    \n    return {\n        "messages": [("assistant", final_response)],\n        "query_execution_time": state["query_execution_time"] + processing_time,\n        "token_usage": {\n            **state.get("token_usage", {}),\n            "response_synthesizer": len(final_response)\n        }\n    }\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-4-define-intelligent-routing",children:"Step 4: Define Intelligent Routing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def route_by_complexity(state: AnalyticsState):\n    """Route based on query complexity and requirements"""\n    complexity = state.get("query_complexity", "simple")\n    \n    if complexity == "simple":\n        return "fast_track"\n    elif state.get("needs_prediction", False):\n        return "prediction_required"\n    elif state.get("needs_external_data", False):\n        return "external_data_required"\n    else:\n        return "standard_processing"\n\ndef determine_next_step(state: AnalyticsState):\n    """Determine next processing step"""\n    if not state.get("query_results"):\n        return "data_executor"\n    elif state.get("needs_external_data", False) and not state.get("enriched_data"):\n        return "external_enricher"\n    elif state.get("needs_prediction", False) and not state.get("predictions"):\n        return "prediction_engine"\n    elif state.get("needs_visualization", False) and not state.get("visualizations"):\n        return "visualization_generator"\n    else:\n        return "response_synthesizer"\n\ndef quality_check(state: AnalyticsState):\n    """Check quality and completeness of results"""\n    confidence = state.get("confidence_score", 0)\n    \n    if confidence  threshold:\n            similar_queries.append((cached_query, similarity))\n    \n    return similar_queries\n'})}),"\n",(0,s.jsxs)(n.h3,{id:"2-token-usage-optimization",children:["2. ",(0,s.jsx)(n.strong,{children:"Token Usage Optimization"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def optimize_llm_calls(state: AnalyticsState):\n    """Optimize LLM calls to reduce token usage"""\n    \n    # Use smaller models for simple tasks\n    def get_optimal_model(task_complexity: str):\n        if task_complexity == "simple":\n            return ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)\n        elif task_complexity == "medium":\n            return ChatOpenAI(model="gpt-4", temperature=0.3, max_tokens=1000)\n        else:\n            return ChatOpenAI(model="gpt-4", temperature=0.3, max_tokens=2000)\n    \n    # Batch similar operations\n    def batch_process_collections(collections: List[str]):\n        """Process multiple collections in single LLM call"""\n        batch_prompt = f"""\n        Generate MongoDB queries for these collections in one response:\n        Collections: {collections}\n        \n        Return as JSON object with collection names as keys.\n        """\n        \n        response = llm.invoke([{"role": "user", "content": batch_prompt}])\n        return json.loads(response.content)\n    \n    # Use prompt templates\n    PROMPT_TEMPLATES = {\n        "simple_query": "Generate MongoDB query for {collection}: {user_query}",\n        "complex_analysis": "Analyze {collection} data for {user_query}. Focus on: {key_metrics}",\n        "prediction": "Predict {target} based on {features} from {collection}"\n    }\n    \n    return state\n'})}),"\n",(0,s.jsxs)(n.h3,{id:"3-advanced-performance-monitoring",children:["3. ",(0,s.jsx)(n.strong,{children:"Advanced Performance Monitoring"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def performance_monitor(state: AnalyticsState):\n    """Monitor and optimize performance"""\n    \n    metrics = {\n        "query_complexity": state.get("query_complexity"),\n        "collections_accessed": len(state.get("collections_accessed", [])),\n        "total_execution_time": state.get("query_execution_time", 0),\n        "token_usage": sum(state.get("token_usage", {}).values()),\n        "cache_hit_rate": state.get("cache_hits", 0) / max(1, len(state.get("collections_accessed", []))),\n        "confidence_score": state.get("confidence_score", 0)\n    }\n    \n    # Log performance metrics\n    log_performance_metrics(metrics)\n    \n    # Adjust strategy based on performance\n    if metrics["total_execution_time"] > 10:  # Too slow\n        return "optimize_performance"\n    elif metrics["token_usage"] > 5000:  # Too expensive\n        return "reduce_token_usage"\n    else:\n        return "continue_normal"\n\ndef log_performance_metrics(metrics: Dict[str, Any]):\n    """Log metrics to monitoring system"""\n    print(f"Performance Metrics: {json.dumps(metrics, indent=2)}")\n    \n    # In production, send to monitoring service\n    # monitoring_service.log_metrics(metrics)\n'})}),"\n",(0,s.jsxs)(n.h3,{id:"4-smart-query-optimization",children:["4. ",(0,s.jsx)(n.strong,{children:"Smart Query Optimization"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def optimize_mongodb_queries(state: AnalyticsState):\n    """Optimize MongoDB queries for better performance"""\n    \n    queries = state.get("generated_queries", [])\n    optimized_queries = []\n    \n    for query in queries:\n        collection = query["collection"]\n        pipeline = query["pipeline"]\n        \n        # Add optimization stages\n        optimized_pipeline = []\n        \n        # Add $match early if possible\n        if not pipeline or pipeline[0].get("$match") is None:\n            optimized_pipeline.append({"$match": {"status": {"$ne": "deleted"}}})\n        \n        # Add original pipeline\n        optimized_pipeline.extend(pipeline)\n        \n        # Add $limit for large datasets\n        if not any("$limit" in stage for stage in pipeline):\n            optimized_pipeline.append({"$limit": 1000})\n        \n        # Add projection to reduce data transfer\n        essential_fields = get_essential_fields(collection, state["original_query"])\n        if essential_fields:\n            optimized_pipeline.append({"$project": {field: 1 for field in essential_fields}})\n        \n        optimized_queries.append({\n            "collection": collection,\n            "pipeline": optimized_pipeline,\n            "estimated_docs": query.get("estimated_docs", 100)\n        })\n    \n    return {"generated_queries": optimized_queries}\n\ndef get_essential_fields(collection: str, user_query: str) -> List[str]:\n    """Determine essential fields based on query"""\n    schema = SCHEMA_INFO.get(collection, {})\n    all_fields = schema.get("fields", [])\n    \n    # Simple keyword matching (in production, use more sophisticated NLP)\n    essential = []\n    for field in all_fields:\n        if field.lower() in user_query.lower():\n            essential.append(field)\n    \n    # Always include ID and common fields\n    essential.extend(["_id", "created_at", "updated_at"])\n    \n    return list(set(essential))\n'})}),"\n",(0,s.jsx)(n.h2,{id:"production-best-practices",children:"Production Best Practices"}),"\n",(0,s.jsxs)(n.h3,{id:"1-scalability-patterns",children:["1. ",(0,s.jsx)(n.strong,{children:"Scalability Patterns"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Horizontal scaling with worker nodes\ndef distribute_work(state: AnalyticsState):\n    """Distribute work across multiple workers"""\n    \n    collections = state["collections_accessed"]\n    \n    # Split collections across workers\n    worker_assignments = {}\n    for i, collection in enumerate(collections):\n        worker_id = f"worker_{i % 3}"  # 3 workers\n        if worker_id not in worker_assignments:\n            worker_assignments[worker_id] = []\n        worker_assignments[worker_id].append(collection)\n    \n    return worker_assignments\n\n# Load balancing\ndef get_least_loaded_worker():\n    """Get worker with lowest current load"""\n    workers = ["worker_1", "worker_2", "worker_3"]\n    loads = {worker: get_worker_load(worker) for worker in workers}\n    return min(loads.items(), key=lambda x: x[1])[0]\n'})}),"\n",(0,s.jsxs)(n.h3,{id:"2-error-recovery-and-resilience",children:["2. ",(0,s.jsx)(n.strong,{children:"Error Recovery and Resilience"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def resilient_query_execution(state: AnalyticsState):\n    """Execute queries with resilience patterns"""\n    \n    queries = state["generated_queries"]\n    results = []\n    \n    for query in queries:\n        max_retries = 3\n        backoff_delay = 1\n        \n        for attempt in range(max_retries):\n            try:\n                # Execute query with timeout\n                result = execute_query_with_timeout(query, timeout=30)\n                results.append(result)\n                break\n                \n            except Exception as e:\n                if attempt == max_retries - 1:\n                    # Final attempt failed, use fallback\n                    fallback_result = get_fallback_data(query["collection"])\n                    results.append(fallback_result)\n                else:\n                    # Retry with exponential backoff\n                    time.sleep(backoff_delay)\n                    backoff_delay *= 2\n    \n    return {"query_results": results}\n\ndef get_fallback_data(collection: str):\n    """Get fallback data when query fails"""\n    return {\n        "collection": collection,\n        "data": generate_mock_data(collection),\n        "count": 50,\n        "fallback": True\n    }\n'})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);